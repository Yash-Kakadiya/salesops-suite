{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae4d34f",
   "metadata": {},
   "source": [
    "# 08: A2A Orchestration: The Autonomous Pipeline ü§ñ\n",
    "\n",
    "This notebook demonstrates the **Grand Orchestration** of the SalesOps Agent Suite (Day 7).\n",
    "\n",
    "Previously, we manually ran each agent in separate notebooks. Now, we introduce the **`A2ACoordinator`**, a master agent that autonomously manages the entire lifecycle:\n",
    "1.  **Ingest** raw data.\n",
    "2.  **Detect** statistical anomalies.\n",
    "3.  **Explain** outliers using parallel AI workers.\n",
    "4.  **Act** by triggering enterprise workflows (Jira/Email).\n",
    "\n",
    "### üéØ Goals\n",
    "1.  **Start Environment:** Ensure the Mock Enterprise Server is running on port 7777.\n",
    "2.  **Execute Pipeline:** Trigger a single `run_pipeline()` command that fans out work to sub-agents.\n",
    "3.  **Verify Autonomy:** Confirm that data flows seamlessly from CSV to Jira Ticket without human intervention.\n",
    "4.  **Inspect Artifacts:** Review the generated `manifest.json` and audit logs.\n",
    "\n",
    "### üèóÔ∏è Components Used\n",
    "* `agents.orchestrator.A2ACoordinator`: The central brain implementing the Sequential & Parallel agent patterns.\n",
    "* `agents.*`: All previously built agents working in concert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a6d0f2",
   "metadata": {},
   "source": [
    "## 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e6dcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YASH\\anaconda3\\envs\\salesops\\Lib\\site-packages\\google\\cloud\\aiplatform\\models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
      "  from google.cloud.aiplatform.utils import gcs_utils\n",
      "2025-11-24 21:41:08,623 - google_adk.google.adk.models.registry - INFO - Updating LLM class for gemini-.* from <class 'google.adk.models.google_llm.Gemini'> to <class 'google.adk.models.google_llm.Gemini'>\n",
      "2025-11-24 21:41:08,625 - google_adk.google.adk.models.registry - INFO - Updating LLM class for projects\\/.+\\/locations\\/.+\\/endpoints\\/.+ from <class 'google.adk.models.google_llm.Gemini'> to <class 'google.adk.models.google_llm.Gemini'>\n",
      "2025-11-24 21:41:08,625 - google_adk.google.adk.models.registry - INFO - Updating LLM class for projects\\/.+\\/locations\\/.+\\/publishers\\/google\\/models\\/gemini.+ from <class 'google.adk.models.google_llm.Gemini'> to <class 'google.adk.models.google_llm.Gemini'>\n",
      "2025-11-24 21:41:08,627 - google_adk.google.adk.models.registry - INFO - Updating LLM class for gemini-.* from <class 'google.adk.models.google_llm.Gemini'> to <class 'google.adk.models.google_llm.Gemini'>\n",
      "2025-11-24 21:41:08,627 - google_adk.google.adk.models.registry - INFO - Updating LLM class for projects\\/.+\\/locations\\/.+\\/endpoints\\/.+ from <class 'google.adk.models.google_llm.Gemini'> to <class 'google.adk.models.google_llm.Gemini'>\n",
      "2025-11-24 21:41:08,627 - google_adk.google.adk.models.registry - INFO - Updating LLM class for projects\\/.+\\/locations\\/.+\\/publishers\\/google\\/models\\/gemini.+ from <class 'google.adk.models.google_llm.Gemini'> to <class 'google.adk.models.google_llm.Gemini'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking Mock Server Status...\n",
      "üöÄ Starting Mock Server (Port 7777)...\n",
      "‚úÖ Mock Server Started Successfully.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from subprocess import Popen\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. Environment Setup\n",
    "# Add project root to path so we can import agents\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from agents.a2a_coordinator import A2ACoordinator\n",
    "\n",
    "# 2. Ensure Mock Server is Running\n",
    "print(\"üîç Checking Mock Server Status...\")\n",
    "try:\n",
    "    requests.get(\"http://localhost:7777/health\")\n",
    "    print(\"‚úÖ Mock Server is already running.\")\n",
    "except:\n",
    "    print(\"üöÄ Starting Mock Server (Port 7777)...\")\n",
    "    log_file = open(\"../outputs/mock_server_orchestrator.log\", \"w\")\n",
    "\n",
    "    # Start process using the current python executable\n",
    "    process = Popen(\n",
    "        [sys.executable, \"-m\", \"uvicorn\", \"tools.mock_server:app\", \"--port\", \"7777\"],\n",
    "        stdout=log_file,\n",
    "        stderr=log_file,\n",
    "        cwd=project_root,\n",
    "    )\n",
    "    time.sleep(5)  # Wait for startup\n",
    "\n",
    "    try:\n",
    "        requests.get(\"http://localhost:7777/health\")\n",
    "        print(\"‚úÖ Mock Server Started Successfully.\")\n",
    "    except:\n",
    "        print(\"‚ùå Failed to start Mock Server. Check logs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83df94c",
   "metadata": {},
   "source": [
    "## 2) Define Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191f30c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Flow Configuration Ready:\n",
      "{\n",
      "  \"id\": \"daily_full_run\",\n",
      "  \"confirm_actions\": true,\n",
      "  \"parallelism\": 3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Flow Config (Sequential Pipeline)\n",
    "flow_config = {\n",
    "    \"id\": \"daily_full_run\",\n",
    "    \"confirm_actions\": True,  # Allow side-effects (sending tickets)\n",
    "    \"parallelism\": 3,  # Fan-out for 3 explainers\n",
    "}\n",
    "\n",
    "inputs = {\"csv_path\": \"../data/raw/superstore.csv\"}\n",
    "\n",
    "# Unique session for this demo run\n",
    "session_id = \"session:demo-user-01\"\n",
    "\n",
    "print(\"‚úÖ Flow Configuration Ready:\")\n",
    "print(json.dumps(flow_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3546605",
   "metadata": {},
   "source": [
    "## 3) Run Coordinator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d37a824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 21:41:31,814 - A2ACoordinator - INFO - Starting Run run_20251124T161131Z_96ecd4\n",
      "2025-11-24 21:41:31,816 - agents.data_ingestor - INFO - Attempting read with encoding='utf-8'...\n",
      "2025-11-24 21:41:31,841 - agents.data_ingestor - WARNING - Encoding 'utf-8' failed. Retrying...\n",
      "2025-11-24 21:41:31,843 - agents.data_ingestor - INFO - Attempting read with encoding='latin1'...\n",
      "2025-11-24 21:41:31,887 - agents.data_ingestor - INFO - Success! Read 9994 rows.\n",
      "2025-11-24 21:41:31,907 - agents.data_ingestor - INFO - Schema validation passed.\n",
      "2025-11-24 21:41:32,006 - agents.data_ingestor - INFO - Snapshot saved successfully to D:\\01. Github\\salesops-suite\\outputs\\runs\\run_20251124T161131Z_96ecd4\\snapshot.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Starting Run... (Session: session:demo-user-01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 21:41:32,291 - agents.anomaly_stats_agent - INFO - Running Global Z-Score Detector on Sales (w=30, t=3.0)\n",
      "2025-11-24 21:41:32,300 - agents.anomaly_stats_agent - INFO - Running Grouped IQR Detector on Region (w=14, k=1.5)\n",
      "2025-11-24 21:41:32,338 - agents.anomaly_stats_agent - INFO - Saved 253 anomalies to D:\\01. Github\\salesops-suite\\outputs\\runs\\run_20251124T161131Z_96ecd4\\anomalies.json\n",
      "2025-11-24 21:41:33,499 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-11-24 21:41:33,501 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-11-24 21:41:33,501 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-11-24 21:41:35,633 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 21:41:35,638 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-11-24 21:41:35,826 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-11-24 21:41:36,650 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-11-24 21:41:37,718 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 21:41:38,030 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 21:41:38,670 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 21:41:38,721 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-11-24 21:41:40,273 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Run ID: run_20251124T161131Z_96ecd4\n",
      "Status: completed\n"
     ]
    }
   ],
   "source": [
    "# 2. Execute the Pipeline\n",
    "coordinator = A2ACoordinator()\n",
    "print(f\"‚ñ∂Ô∏è Starting Run... (Session: {session_id})\")\n",
    "\n",
    "manifest = coordinator.run(flow_config, inputs, session_id)\n",
    "\n",
    "print(f\"\\n‚úÖ Run ID: {manifest['run_id']}\")\n",
    "print(f\"Status: {manifest['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55989ec6",
   "metadata": {},
   "source": [
    "## 4) Tail Observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20c4d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Latest Entry in ../outputs/observability/a2a_runs.jsonl ---\n",
      "Run ID: run_20251124T161131Z_96ecd4\n",
      "Tasks: ['Ingestor', 'Detector', 'Explainer', 'Actor']\n",
      "Artifacts: {\n",
      "  \"snapshot\": \"D:\\\\01. Github\\\\salesops-suite\\\\outputs\\\\runs\\\\run_20251124T161131Z_96ecd4\\\\snapshot.parquet\",\n",
      "  \"anomalies\": \"D:\\\\01. Github\\\\salesops-suite\\\\outputs\\\\runs\\\\run_20251124T161131Z_96ecd4\\\\anomalies.json\",\n",
      "  \"explanations\": \"D:\\\\01. Github\\\\salesops-suite\\\\outputs\\\\runs\\\\run_20251124T161131Z_96ecd4\\\\enriched_anomalies.json\",\n",
      "  \"actions_log\": \"D:\\\\01. Github\\\\salesops-suite\\\\outputs\\\\runs\\\\run_20251124T161131Z_96ecd4\\\\actions.jsonl\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 3. Inspect the Master Run Manifest\n",
    "log_path = \"../outputs/observability/a2a_runs.jsonl\"\n",
    "print(f\"--- Latest Entry in {log_path} ---\")\n",
    "\n",
    "with open(log_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    if lines:\n",
    "        last_run = json.loads(lines[-1])\n",
    "        print(f\"Run ID: {last_run['run_id']}\")\n",
    "        print(f\"Tasks: {[t['task_id'] for t in last_run['tasks']]}\")\n",
    "        print(f\"Artifacts: {json.dumps(last_run['artifacts'], indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bdf7cf",
   "metadata": {},
   "source": [
    "## 5) Inspect Outputs (Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3313c290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- üß† Generated Explanations (Top 1) ---\n",
      "Anomaly: iqr_South_2014-03-18_s24\n",
      "Explanation: South region sales of 23,661.23 significantly exceed the expected value of 1,159.38, indicated by a high anomaly score of 24.21.\n",
      "\n",
      "--- ‚ö° Executed Actions (Tail) ---\n",
      "Action Type: create_ticket\n",
      "Result: success (HTTP 201)\n"
     ]
    }
   ],
   "source": [
    "# 4. Load Generated Artifacts\n",
    "explanations_path = \"../outputs/runs/\" + manifest[\"run_id\"] + \"/enriched_anomalies.json\"\n",
    "actions_path = \"../outputs/actions/actions.jsonl\"\n",
    "\n",
    "print(\"\\n--- üß† Generated Explanations (Top 1) ---\")\n",
    "if os.path.exists(explanations_path):\n",
    "    with open(explanations_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        if data:\n",
    "            print(f\"Anomaly: {data[0].get('anomaly_id')}\")\n",
    "            print(f\"Explanation: {data[0].get('explanation_short')}\")\n",
    "\n",
    "print(\"\\n--- ‚ö° Executed Actions (Tail) ---\")\n",
    "if os.path.exists(actions_path):\n",
    "    with open(actions_path, \"r\") as f:\n",
    "        last_action = json.loads(f.readlines()[-1])\n",
    "        print(f\"Action Type: {last_action['type']}\")\n",
    "        print(\n",
    "            f\"Result: {last_action['result']['status']} (HTTP {last_action['result'].get('http_code')})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd75fa9",
   "metadata": {},
   "source": [
    "## 6) Error Demo (Chaos Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a19414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí• Enabling Chaos Monkey (Simulating 500 Errors)...\n",
      "‚ñ∂Ô∏è Re-attempting Actions with Chaos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 21:42:25,921 - agents.action_agent - WARNING - Server Error 500. Retrying...\n",
      "2025-11-24 21:42:29,173 - agents.action_agent - WARNING - Server Error 500. Retrying...\n",
      "2025-11-24 21:42:33,482 - agents.action_agent - WARNING - Server Error 500. Retrying...\n",
      "2025-11-24 21:42:39,548 - agents.action_agent - WARNING - Server Error 500. Retrying...\n",
      "2025-11-24 21:42:42,840 - agents.action_agent - WARNING - Server Error 500. Retrying...\n",
      "2025-11-24 21:42:47,012 - agents.action_agent - WARNING - Server Error 500. Retrying...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught Expected Error: 'result'\n",
      "‚úÖ Chaos Disabled.\n"
     ]
    }
   ],
   "source": [
    "# 5. Simulate a Component Failure\n",
    "print(\"üí• Enabling Chaos Monkey (Simulating 500 Errors)...\")\n",
    "requests.post(\n",
    "    \"http://localhost:7777/admin/chaos\", json={\"enabled\": True, \"failure_rate\": 1.0}\n",
    ")\n",
    "\n",
    "# Re-run the Action phase logic specifically to see failure handling\n",
    "# (Using the same coordinator instance to simulate a retry)\n",
    "print(\"‚ñ∂Ô∏è Re-attempting Actions with Chaos...\")\n",
    "try:\n",
    "    # We manually trigger just the action step for the demo speed\n",
    "    # In a real A2A run, the coordinator would handle this\n",
    "    with open(explanations_path, \"r\") as f:\n",
    "        anoms = json.load(f)[:1]  # Just 1 for speed\n",
    "\n",
    "    # This should fail/retry and log errors\n",
    "    res = coordinator.actor.run_batch(anoms)\n",
    "    print(\n",
    "        f\"Result with Chaos: {res[0]['result']['status']} (Reason: {res[0]['result'].get('reason')})\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Caught Expected Error: {e}\")\n",
    "\n",
    "# Reset Chaos\n",
    "requests.post(\"http://localhost:7777/admin/chaos\", json={\"enabled\": False})\n",
    "print(\"‚úÖ Chaos Disabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f436f296",
   "metadata": {},
   "source": [
    "## 7) Idempotency Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1efddd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 21:42:59,198 - A2ACoordinator - INFO - Starting Run run_20251124T161131Z_96ecd4\n",
      "2025-11-24 21:42:59,198 - agents.data_ingestor - INFO - Attempting read with encoding='utf-8'...\n",
      "2025-11-24 21:42:59,223 - agents.data_ingestor - WARNING - Encoding 'utf-8' failed. Retrying...\n",
      "2025-11-24 21:42:59,224 - agents.data_ingestor - INFO - Attempting read with encoding='latin1'...\n",
      "2025-11-24 21:42:59,250 - agents.data_ingestor - INFO - Success! Read 9994 rows.\n",
      "2025-11-24 21:42:59,261 - agents.data_ingestor - INFO - Schema validation passed.\n",
      "2025-11-24 21:42:59,288 - agents.data_ingestor - INFO - Snapshot saved successfully to D:\\01. Github\\salesops-suite\\outputs\\runs\\run_20251124T161131Z_96ecd4\\snapshot.parquet\n",
      "2025-11-24 21:42:59,324 - agents.anomaly_stats_agent - INFO - Running Global Z-Score Detector on Sales (w=30, t=3.0)\n",
      "2025-11-24 21:42:59,329 - agents.anomaly_stats_agent - INFO - Running Grouped IQR Detector on Region (w=14, k=1.5)\n",
      "2025-11-24 21:42:59,361 - agents.anomaly_stats_agent - INFO - Saved 253 anomalies to D:\\01. Github\\salesops-suite\\outputs\\runs\\run_20251124T161131Z_96ecd4\\anomalies.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Re-running the EXACT same flow (Idempotency Check)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 21:43:00,384 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-11-24 21:43:00,385 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-11-24 21:43:00,385 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-11-24 21:43:02,573 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 21:43:02,695 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 21:43:02,695 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 21:43:03,580 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-11-24 21:43:03,709 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-11-24 21:43:05,589 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-24 21:43:05,681 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 2 Status: completed\n",
      "‚úÖ Idempotency Run Complete. Check server logs for 'Replay' confirmation.\n"
     ]
    }
   ],
   "source": [
    "# 6. Idempotency Verify\n",
    "print(\"üîÑ Re-running the EXACT same flow (Idempotency Check)...\")\n",
    "\n",
    "# Rerun the coordinator with the SAME session and inputs\n",
    "manifest_2 = coordinator.run(flow_config, inputs, session_id)\n",
    "\n",
    "# Check the Action Log: We should NOT see new tickets created, but 'success' results from replay\n",
    "print(f\"\\nRun 2 Status: {manifest_2['status']}\")\n",
    "\n",
    "# Verify in Audit Log (check for 'Replay' or same IDs)\n",
    "# Note: Our Mock Server logs 'Replay' in its console, and returns the SAME ticket_id.\n",
    "# We can verify by checking if ticket IDs are identical if we stored them,\n",
    "# or relying on the Server logs/audit trail showing no new resource creation.\n",
    "print(\"‚úÖ Idempotency Run Complete. Check server logs for 'Replay' confirmation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b090be",
   "metadata": {},
   "source": [
    "## ‚è≠Ô∏è Next Step: The \"Learning\" Agent (Memory Bank)\n",
    "\n",
    "Success! We have built a fully autonomous pipeline.\n",
    "1.  **Ingest** ‚Üí **Detect** ‚Üí **Explain** ‚Üí **Act**.\n",
    "2.  The Coordinator handled errors, retries, and parallel fan-out.\n",
    "3.  We have a complete audit trail in `../outputs/observability`.\n",
    "\n",
    "**However, our agent is \"Amnesic\".**\n",
    "If the *same* anomaly happens next month, the agent will re-analyze it from scratch. It won't remember: *\"Oh, we saw this last time, and the fix was to email the vendor.\"*\n",
    "\n",
    "In **Day 8**, we will build the **Memory Bank**.\n",
    "We will give our agents **Long-Term Semantic Memory** so they can:\n",
    "* **Recall** past anomalies.\n",
    "* **Retrieve** successful actions from history.\n",
    "* **Learn** from previous resolutions.\n",
    "\n",
    "üëâ **Proceed to `notebooks/09_memory_learning.ipynb`.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salesops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
